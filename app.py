"""
ğŸŒ Avrupa Tur Rehberi Chatbot
AI-powered RAG chatbot for European city travel information
"""

import os
from dotenv import load_dotenv
import gradio as gr
from langchain_groq import ChatGroq
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains.question_answering import load_qa_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
import wikipedia

# .env dosyasÄ±ndan API key'i yÃ¼kle
load_dotenv()

# API KEY kontrolÃ¼
if "GROQ_API_KEY" not in os.environ:
    print("âŒ GROQ_API_KEY bulunamadÄ±!")
    print("ğŸ“ .env dosyasÄ± oluÅŸturup API key'inizi ekleyin")
    raise Exception("GROQ_API_KEY gerekli!")

print("ğŸ”§ Sistem hazÄ±rlanÄ±yor...\n")

# TÃ¼rkÃ§e Wikipedia
wikipedia.set_lang("tr")

# === AI MODELLERÄ° ===
print("ğŸ¤– AI modelleri yÃ¼kleniyor...")

llm = ChatGroq(
    model="llama-3.3-70b-versatile",
    temperature=0.7
)

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)
print("âœ“ Modeller hazÄ±r\n")

# === VERÄ° TOPLAMA ===
print("ğŸ“¥ Wikipedia'dan Avrupa ÅŸehirleri bilgisi Ã§ekiliyor...\n")

cities = [
    "Londra", "Paris", "BrÃ¼ksel", "Amsterdam", "LÃ¼ksemburg",
    "Oslo", "Stockholm", "Kopenhag", "Helsinki", "Reykjavik",
    "Lizbon", "Madrid", "Roma", "Atina", "Valletta",
    "Viyana", "Berlin", "Bern", "Prag", "Bratislava", "BudapeÅŸte",
    "Barselona", "Milan", "Valencia", "Munih"
]

documents = []
for city in cities:
    try:
        print(f"  â€¢ {city}...", end=" ")
        summary = wikipedia.summary(city, sentences=5)
        page = wikipedia.page(city)
        
        content = f"""
ÅEHÄ°R: {city}
Ã–ZET: {summary}
DETAYLAR: {page.content[:1500]}
"""
        documents.append(Document(
            page_content=content, 
            metadata={'city': city}
        ))
        print("âœ“")
    except:
        print("âœ—")
        continue

print(f"\nâœ“ {len(documents)} ÅŸehir yÃ¼klendi\n")

# === VEKTÃ–R VERÄ°TABANI ===
print("ğŸ”® VektÃ¶r veritabanÄ± oluÅŸturuluyor...")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)
texts = text_splitter.split_documents(documents)
vector_store = FAISS.from_documents(texts, embeddings)
print(f"âœ“ HazÄ±r ({len(texts)} parÃ§a)\n")

# === SORU-CEVAP ZÄ°NCÄ°RÄ° ===
prompt_template = """
Sen bir Avrupa seyahat danÄ±ÅŸmanÄ±sÄ±n. Verilen bilgileri kullanarak soruya samimi ve detaylÄ± cevap ver.

BaÄŸlam: {context}
Soru: {question}
Cevap:
"""
prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
chain = load_qa_chain(llm, chain_type="stuff", prompt=prompt)

# === CHATBOT FONKSÄ°YONU ===
def chatbot_response(user_message, history):
    try:
        docs = vector_store.similarity_search(user_message, k=3)
        response = chain.invoke({
            "input_documents": docs,
            "question": user_message
        })
        return response["output_text"]
    except Exception as e:
        return f"âŒ Hata: {str(e)}"

# === GRADIO ARAYÃœZÃœ ===
print("ğŸš€ WEB ARAYÃœZÃœ BAÅLATILIYOR...\n")

demo = gr.ChatInterface(
    fn=chatbot_response,
    title="ğŸŒ Avrupa Tur Rehberi Chatbot",
    description="Merhaba! Ben Avrupa ÅŸehirleri hakkÄ±nda bilgi veren bir chatbot'um.",
    examples=[
        "Roma'da ne yapmalÄ±yÄ±m?",
        "Paris'te gezilecek yerler neler?",
        "Barselona'da hangi yemekleri denemeli?"
    ]
)

if __name__ == "__main__":
    demo.launch(share=True, debug=False)
